{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srishmaalladi/Katha-vachak/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOd2hir9TYP2",
        "outputId": "cb2f9847-4125-48fb-b1c0-6381d9adcf97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.10/dist-packages (2024.11.7)\n",
            "Requirement already satisfied: unsloth-zoo>=2024.11.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2024.11.5)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1+cu121)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.0.28.post3)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.44.1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.9.1)\n",
            "Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.46.2)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.1.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.1.1)\n",
            "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.12.1)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.13.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.26.2)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (0.20.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (1.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: flask_cors in /usr/local/lib/python3.10/dist-packages (5.0.0)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask_cors) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=0.9->flask_cors) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install unsloth\n",
        "!pip install pyngrok\n",
        "!pip install flask_cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuGEKVm_ZaF8",
        "outputId": "49ff7a24-e12a-4b69-ebd9-0153a53e8b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6dMksC4ZxD9",
        "outputId": "04dcda4c-6473-44c5-f19d-786ddf0ea7ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "==((====))==  Unsloth 2024.11.7: Fast Llama patching. Transformers = 4.46.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.11.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "model,tokenizer=FastLanguageModel.from_pretrained('/content/drive/MyDrive/final_model')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgNLZWXFf7WE",
        "outputId": "3489032b-8bb5-4482-ab57-03f17a926c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pillow\n",
        "!pip install transformers\n",
        "!pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMHV4oDhbwhy",
        "outputId": "ad7b4ac4-49f8-467a-a49d-49ec52567d98"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://tick-knowing-monthly.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            "To access the global link, please click https://214d-34-80-211-38.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "ERROR:__main__:Exception on / [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1473, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 882, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 880, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 865, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
            "  File \"<ipython-input-11-a2180e948e54>\", line 84, in generate_story\n",
            "    inputs = tokenizer([user_input], return_tensors=\"pt\").to(\"cuda\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 818, in to\n",
            "    self.data = {k: v.to(device=device) for k, v in self.data.items() if isinstance(v, torch.Tensor)}\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\", line 818, in <dictcomp>\n",
            "    self.data = {k: v.to(device=device) for k, v in self.data.items() if isinstance(v, torch.Tensor)}\n",
            "RuntimeError: CUDA error: device-side assert triggered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "INFO:werkzeug:127.0.0.1 - - [19/Nov/2024 10:18:44] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "from unsloth import FastLanguageModel\n",
        "from PIL import Image\n",
        "from transformers import TextStreamer, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from flask_cors import CORS\n",
        "import re\n",
        "import base64\n",
        "import requests\n",
        "import torch\n",
        "import io\n",
        "\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "PORT=5000\n",
        "\n",
        "# Set up ngrok for public access\n",
        "ngrok.set_auth_token(\"2nTaRxHGdDYre0DMbc02Do1TzPz_5dYfMsAZ8bfMidRijWmY7\")\n",
        "# NGROK_DOMAIN = \"oyster-known-porpoise.ngrok-free.app \"\n",
        "NGROK_DOMAIN=\"tick-knowing-monthly.ngrok-free.app\"\n",
        "\n",
        "\n",
        "tunnel_config = {\n",
        "    \"addr\": PORT,\n",
        "    \"hostname\": NGROK_DOMAIN\n",
        "}\n",
        "public_url = ngrok.connect(**tunnel_config)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "\n",
        "# Print the public URL for external access\n",
        "print(f\"To access the global link, please click {public_url}\")\n",
        "\n",
        "# Load the model and tokenizer\n",
        "story_keywords = [\"story\", \"generate\", \"tale\", \"narrative\", \"adventure\"]\n",
        "\n",
        "def contains_story_keywords(user_input):\n",
        "    \"\"\"Check for any story-related keywords in the user input\"\"\"\n",
        "    return any(keyword in user_input.lower() for keyword in story_keywords)\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    \"\"\"Split text into sentences using regular expressions\"\"\"\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "    return sentences\n",
        "\n",
        "def group_sentences_into_scenes(sentences, group_size=4):\n",
        "\n",
        "\n",
        "    \"\"\"Group sentences into scenes with specified group size (4 by default)\"\"\"\n",
        "    scenes = [' '.join(sentences[i:i+group_size]) for i in range(0, len(sentences), group_size)]\n",
        "    print(f\"group_sentences_into_scenes: {scenes}\")\n",
        "    return scenes\n",
        "\n",
        "def query_image_generation(prompt):\n",
        "    print(prompt)\n",
        "    API_URL= \"https://api-inference.huggingface.co/models/ZB-Tech/Text-to-Image\"\n",
        "    headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "    \"\"\"Query Hugging Face Text-to-Image API to generate an image for the scene\"\"\"\n",
        "    response = requests.post(API_URL, headers=headers, json={\"inputs\": prompt})\n",
        "    if response.status_code == 200:\n",
        "        return Image.open(io.BytesIO(response.content))  # Return the image from the response\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return None\n",
        "\n",
        "def encode_image_to_base64(image):\n",
        "    \"\"\"Convert a PIL image to a Base64 string\"\"\"\n",
        "    buffered = io.BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")  # Save image as PNG\n",
        "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")  # Return Base64 string\n",
        "\n",
        "\n",
        "@app.route(\"/\", methods=[\"POST\"])\n",
        "def generate_story():\n",
        "    user_input = request.json.get(\"input\", \"\")  # Get user input from the POST request\n",
        "    # Check if the input contains story-related keywords\n",
        "    if contains_story_keywords(user_input):\n",
        "        # Prepare inputs for the model (direct input from the user)\n",
        "        inputs = tokenizer([user_input], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "        # Enable native 2x faster inference using FastLanguageModel\n",
        "        FastLanguageModel.for_inference(model)  # This line is essential for performance\n",
        "\n",
        "        # Generate the story\n",
        "        generated_story = model.generate(**inputs)\n",
        "\n",
        "\n",
        "        # Decode the generated tokens to text\n",
        "        story_text = tokenizer.decode(generated_story[0], skip_special_tokens=True)\n",
        "        story_text = story_text.replace(\"\\n\", \" \")\n",
        "        while user_input in story_text:\n",
        "            story_text = story_text.replace(user_input, \"\").strip()\n",
        "\n",
        "        sentences = split_into_sentences(story_text)\n",
        "        scenes = group_sentences_into_scenes(sentences)\n",
        "        story_with_images = []\n",
        "        for i, scene in enumerate(scenes):\n",
        "            print(f\"Generating image for scene {i+1}: {scene}\")\n",
        "            image = query_image_generation(scene)  # Pass each scene to the API\n",
        "            if image:\n",
        "                encoded_image = encode_image_to_base64(image)  # Encode the image to Base64\n",
        "                story_with_images.append({\n",
        "                    \"scene\": scene,  # Text of the scene\n",
        "                    \"image\": encoded_image  # Base64 encoded image\n",
        "                })\n",
        "\n",
        "        # Return the story with images in the response\n",
        "        return jsonify(story_with_images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "        # User input does not contain story-related keywords; provide an alternative response\n",
        "        return jsonify({\"message\": \"I'm trained to generate stories. Your input doesn't seem to ask for one.\"})\n",
        "\n",
        "# Run the Flask app\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ai-JGSNRGwz"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "from unsloth import FastLanguageModel\n",
        "from PIL import Image\n",
        "from transformers import TextStreamer, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from flask_cors import CORS\n",
        "import re\n",
        "import base64\n",
        "import requests\n",
        "import io\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "PORT = 5000\n",
        "\n",
        "# Set up ngrok for public access\n",
        "ngrok.set_auth_token(\"2nTaRxHGdDYre0DMbc02Do1TzPz_5dYfMsAZ8bfMidRijWmY7\")\n",
        "public_url = ngrok.connect(PORT)  # Automatically generates a random public URL\n",
        "\n",
        "# Print the public URL for external access\n",
        "print(f\"To access the global link, please click {public_url}\")\n",
        "\n",
        "# Load the model and tokenizer\n",
        "story_keywords = [\"story\", \"generate\", \"tale\", \"narrative\", \"adventure\"]\n",
        "\n",
        "def contains_story_keywords(user_input):\n",
        "    \"\"\"Check for any story-related keywords in the user input\"\"\"\n",
        "    return any(keyword in user_input.lower() for keyword in story_keywords)\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    \"\"\"Split text into sentences using regular expressions\"\"\"\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "    return sentences\n",
        "\n",
        "def group_sentences_into_scenes(sentences, group_size=4):\n",
        "    \"\"\"Group sentences into scenes with specified group size (4 by default)\"\"\"\n",
        "    scenes = [' '.join(sentences[i:i+group_size]) for i in range(0, len(sentences), group_size)]\n",
        "    print(f\"group_sentences_into_scenes: {scenes}\")\n",
        "    return scenes\n",
        "\n",
        "def query_image_generation(prompt):\n",
        "    print(prompt)\n",
        "    API_URL = \"https://api-inference.huggingface.co/models/ZB-Tech/Text-to-Image\"\n",
        "    headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "    \"\"\"Query Hugging Face Text-to-Image API to generate an image for the scene\"\"\"\n",
        "    response = requests.post(API_URL, headers=headers, json={\"inputs\": prompt})\n",
        "    if response.status_code == 200:\n",
        "        return Image.open(io.BytesIO(response.content))  # Return the image from the response\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return None\n",
        "\n",
        "def encode_image_to_base64(image):\n",
        "    \"\"\"Convert a PIL image to a Base64 string\"\"\"\n",
        "    buffered = io.BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")  # Save image as PNG\n",
        "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")  # Return Base64 string\n",
        "\n",
        "@app.route(\"/\", methods=[\"POST\"])\n",
        "def generate_story():\n",
        "    user_input = request.json.get(\"input\", \"\")  # Get user input from the POST request\n",
        "    # Check if the input contains story-related keywords\n",
        "    if contains_story_keywords(user_input):\n",
        "        # Prepare inputs for the model (direct input from the user)\n",
        "        inputs = tokenizer([user_input], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "        # Enable native 2x faster inference using FastLanguageModel\n",
        "        FastLanguageModel.for_inference(model)  # This line is essential for performance\n",
        "\n",
        "        # Generate the story\n",
        "        generated_story = model.generate(**inputs)\n",
        "\n",
        "        # Decode the generated tokens to text\n",
        "        story_text = tokenizer.decode(generated_story[0], skip_special_tokens=True)\n",
        "        story_text = story_text.replace(\"\\n\", \" \")\n",
        "        while user_input in story_text:\n",
        "            story_text = story_text.replace(user_input, \"\").strip()\n",
        "\n",
        "        sentences = split_into_sentences(story_text)\n",
        "        scenes = group_sentences_into_scenes(sentences)\n",
        "        story_with_images = []\n",
        "        for i, scene in enumerate(scenes):\n",
        "            print(f\"Scene {i+1}: {scene}\")\n",
        "            image = query_image_generation(scene)  # Pass each scene to the API\n",
        "            if image:\n",
        "                encoded_image = encode_image_to_base64(image)  # Encode the image to Base64\n",
        "                story_with_images.append({\n",
        "                    \"scene\": scene,  # Text of the scene\n",
        "                    \"image\": encoded_image  # Base64 encoded image\n",
        "                })\n",
        "\n",
        "        # Return the story with images in the response\n",
        "        return jsonify(story_with_images)\n",
        "    else:\n",
        "        # User input does not contain story-related keywords; provide an alternative response\n",
        "        return jsonify({\"message\": \"I'm trained to generate stories. Your input doesn't seem to ask for one.\"})\n",
        "\n",
        "# Run the Flask app\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(port=PORT)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}